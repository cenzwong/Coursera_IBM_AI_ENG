{"cells":[{"cell_type":"markdown","source":["d-sandbox\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 400px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c6bc3461-2af6-4dfe-b9f2-8b3ed667c5e4"}}},{"cell_type":"markdown","source":["# Partitioning\n1. Get partitions and cores\n1. Repartition DataFrames\n1. Configure default shuffle partitions\n\n##### Methods\n- DataFrame (<a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">Python</a>/<a href=\"http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/Dataset.html\" target=\"_blank\">Scala</a>): `repartition`, `coalesce`, `rdd.getNumPartitions`\n- SparkConf (<a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkConf.html?#pyspark.SparkConf\" target=\"_blank\">Python</a>/<a href=\"http://spark.apache.org/docs/latest/api/scala/org/apache/spark/SparkConf.html\" target=\"_blank\">Scala</a>): `get`, `set`\n- SparkSession (<a href=\"https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#spark-session-apis\" target=\"_blank\">Python</a>/<a href=\"http://spark.apache.org/docs/latest/api/scala/org/apache/spark/sql/SparkSession.html\" target=\"_blank\">Scala</a>): `sparkContext.defaultParallelism`\n\n##### SparkConf Parameters\n- `spark.sql.shuffle.partitions`, `spark.sql.adaptive.enabled`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25cad038-f638-4be1-bb65-d0f1de678921"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9737cd2a-bcd1-45a0-bf28-c0c877a44635"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Datasets mounted and student environment set up","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{"isDbfsCommandResult":false},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Datasets mounted and student environment set up"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Get partitions and cores\n\nUse an `rdd` method to get the number of DataFrame partitions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0da26ba5-e4a7-4d1c-8173-99fe154babe4"}}},{"cell_type":"code","source":["df = spark.read.parquet(eventsPath)\ndf.rdd.getNumPartitions()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"502d0c45-f8df-4966-a70a-030826c797bc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[4]: 4","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[4]: 4"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Access SparkContext through SparkSession to get the number of cores or slots\n\nSparkContext is also provided in Databricks notebooks as the variable `sc`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26365422-eed4-463f-ba2e-fecd1377cadd"}}},{"cell_type":"code","source":["print(spark.sparkContext.defaultParallelism)\n# print(sc.defaultParallelism)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9bcbfdd6-b4d6-4f95-a96d-84ab187b9c26"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"8\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["8\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Repartition DataFrame"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b508e5e7-4f8b-4083-94a3-0e1da2b65e86"}}},{"cell_type":"markdown","source":["#### `repartition`\nReturns a new DataFrame that has exactly `n` partitions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f8cbecf4-f3a8-48de-b019-cba5492e01c9"}}},{"cell_type":"code","source":["repartitionedDF = df.repartition(8)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30019195-465f-468d-88d4-39257c0dfcfb"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["repartitionedDF.rdd.getNumPartitions()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e7c7fb1-ccc7-4054-b17a-582df60d1180"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[7]: 8","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[7]: 8"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["#### `coalesce`\nReturns a new DataFrame that has exactly `n` partitions, when the fewer partitions are requested\n\nIf a larger number of partitions is requested, it will stay at the current number of partitions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0eb8c79d-8739-44f9-acb4-c24f3e87ed87"}}},{"cell_type":"code","source":["coalesceDF = df.coalesce(8)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9b186cf-47f3-4b8d-b17f-f2a21ba23264"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["coalesceDF.rdd.getNumPartitions()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6a6c884d-bb3f-4462-a02b-5fd2f63b4f05"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[9]: 4","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[9]: 4"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Configure default shuffle partitions\n\nUse `SparkConf` to access the spark configuration parameter for default shuffle partitions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b1525147-3fe2-4859-ae0a-dc12f203fe59"}}},{"cell_type":"code","source":["spark.conf.get(\"spark.sql.shuffle.partitions\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"062dbcb6-04a8-42e6-b118-25e665009315"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[10]: '200'","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[10]: '200'"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Configure default shuffle partitions to match the number of cores"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"60343362-5c9a-4049-bc68-f5e9031cd19f"}}},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"605e31d2-48fc-48d1-a5ec-5a9c3c65ca57"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["###![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) Adaptive Query Execution\n\nIn Spark 3, <a href=\"https://spark.apache.org/docs/latest/sql-performance-tuning.html#adaptive-query-execution\" target=\"_blank\">AQE</a> is now able to <a href=\"https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html\" target=\"_blank\"> dynamically coalesce shuffle partitions</a> at runtime\n\nSpark SQL can use `spark.sql.adaptive.enabled` to control whether AQE is turned on/off (disabled by default)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d15a2939-c3ad-42de-ab54-2107977cef1f"}}},{"cell_type":"code","source":["spark.conf.get(\"spark.sql.adaptive.enabled\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e715c9f-5873-4fd5-a23e-365cbd3d98b6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[12]: 'true'","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[12]: 'true'"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Clean up classroom"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"211c45b4-42d1-484b-bf87-e1fd4d2b0402"}}},{"cell_type":"code","source":["%run ./Includes/Classroom-Cleanup\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"387cd797-292c-4440-96fe-1e94702eacfe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Dropped database and removed files in working directory","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["Dropped database and removed files in working directory"]},"transient":null}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"3.3 Partitioning","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2610767701418556}},"nbformat":4,"nbformat_minor":0}
